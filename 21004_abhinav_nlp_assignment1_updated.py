# -*- coding: utf-8 -*-
"""21004_Abhinav_nlp_assignment1_updated.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xWLIfJV2dqs8yw1CVMKybWeMIfn4IJmW
"""

!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/train_split.csv
!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/test_split.csv

import pandas as pd
import re
from sklearn.feature_extraction.text import CountVectorizer
import nltk
from nltk.corpus import stopwords
import warnings



nltk.download('stopwords')

stop_words = set(stopwords.words('english'))

train_df = pd.read_csv("/content/train_split.csv")
test_df = pd.read_csv("/content/test_split.csv")

emotion_patterns = {
    "Joy": r'\b(happy|joy|excited|delight|pleasure|glad)\b',
    "Sadness": r'\b(sad|unhappy|sorrow|depressed|grief)\b',
    "Fear": r'\b(scared|afraid|frightened|fear|panic)\b',
    "Anger": r'\b(angry|mad|furious|rage|irritated)\b',
    "Surprise": r'\b(shocked|surprised|astonished|amazed)\b',
}


def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    text = text.lower()
    text = ' '.join(word for word in text.split() if word not in stop_words)

    return text


train_df['cleaned_text'] = train_df['text'].apply(preprocess_text)
test_df['cleaned_text'] = test_df['text'].apply(preprocess_text)

# here this preprocess function is cleaning data by lowering the case , removing space  , stopwards and special characters etc.

def regex_features(text):
    joy_match = 1 if re.search(r'(happy|joy|delight|cheerful|pleasure)', text) else 0
    fear_match = 1 if re.search(r'(scared|fear|afraid|nervous|terrified)', text) else 0
    anger_match = 1 if re.search(r'(angry|furious|rage|irritated|annoyed)', text) else 0
    sadness_match = 1 if re.search(r'(sad|sorrow|grief|unhappy|miserable)', text) else 0
    surprise_match = 1 if re.search(r'(surprise|amazed|astonished|shocked|stunned)', text) else 0

    return [joy_match, fear_match, anger_match, sadness_match, surprise_match]

train_df['regex_features'] = train_df['cleaned_text'].apply(regex_features)
test_df['regex_features'] = test_df['cleaned_text'].apply(regex_features)

# Word-level n-gram
word_vectorizer = CountVectorizer(ngram_range=(2, 3))
Xtrain_word_ngrams = word_vectorizer.fit_transform(train_df['cleaned_text'])  # fit and transform on train
Xtest_word_ngrams = word_vectorizer.transform(test_df['cleaned_text'])    # only transform on test
# Character-level n-gram
char_vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 5))
Xtrain_char_ngrams = char_vectorizer.fit_transform(train_df['cleaned_text'])   # fit and transform on train
Xtest_char_ngrams = char_vectorizer.transform(test_df['cleaned_text'])    # only transform on test

#Combine regex and n-gram features
regex_train_features_matrix = pd.DataFrame(train_df['regex_features'].tolist())
regex_test_features_matrix = pd.DataFrame(test_df['regex_features'].tolist())

combined_train_features = pd.concat([pd.DataFrame(Xtrain_word_ngrams.toarray()), pd.DataFrame(Xtrain_char_ngrams.toarray()), regex_train_features_matrix], axis=1)
combined_test_features = pd.concat([pd.DataFrame(Xtest_word_ngrams.toarray()), pd.DataFrame(Xtest_char_ngrams.toarray()), regex_test_features_matrix], axis=1)

"""# Machine Learning Methods"""

#Using Multilabel Classification with Scikit-Learn

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.multioutput import MultiOutputClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, f1_score, classification_report
import pandas as pd

X_train = combined_train_features
X_test = combined_test_features

y_train = train_df[['Joy', 'Sadness', 'Fear', 'Anger', 'Surprise']]
y_test = test_df[['Joy', 'Sadness', 'Fear', 'Anger', 'Surprise']]



def evaluate_model(model, X_train, y_train, X_test, y_test):
    multi_target_model = MultiOutputClassifier(model)
    multi_target_model.fit(X_train, y_train)
    predictions = multi_target_model.predict(X_test)


    accuracy = accuracy_score(y_test, predictions)
    macro_f1 = f1_score(y_test, predictions, average='macro', zero_division=0)


    report = classification_report(y_test, predictions, target_names=['Joy', 'Sadness', 'Fear', 'Anger', 'Surprise'], zero_division=0)

    return accuracy, macro_f1, report

#given models to test with MultiOutputClassifier
models = {
   "Naive Bayes": MultinomialNB(alpha=0.1),
   "Random Forest": RandomForestClassifier(n_estimators=50),
  #  "SVM": SVC(kernel='linear',C=1),
  # "Logistic Regression": LogisticRegression(C=10, solver='saga', max_iter=200)
}



for model_name, model in models.items():
    print(f"Evaluating {model_name}...")
    accuracy, macro_f1, report = evaluate_model(model, X_train, y_train, X_test, y_test)
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Macro F1 Score: {macro_f1:.4f}")
    print(report)
    print("-" * 80)